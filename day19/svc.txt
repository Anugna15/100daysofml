Support Vector Machine (SVM) – Classification and Regression

### 🔹 Support Vector Machine (SVM)

SVM is a supervised learning algorithm used for both classification and regression. It aims to find the optimal hyperplane that maximally separates classes in a dataset.

#### Key Concepts:

* **Hyperplane**: A decision boundary that separates different classes.
* **Support Vectors**: Data points that lie closest to the hyperplane and influence its orientation.
* **Kernel Trick**: Maps input data into a higher-dimensional space to make it linearly separable. Common kernels include:

  * `linear`
  * `rbf` (Radial Basis Function)

### 🔹 SVM for Classification vs Regression

* **SVC (Support Vector Classification)**: Classifies data by finding the best separating hyperplane.
* **SVR (Support Vector Regression)**: Predicts continuous values by fitting the best hyperplane within a margin of tolerance.

### 🔹 Evaluation Metrics

* **Classification**:

  * Accuracy
  * Confusion Matrix
* **Regression**:

  * Mean Squared Error (MSE)

---


### 📦 Importing Libraries

```python
import pandas as pd
from sklearn.datasets import load_iris, fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, mean_squared_error
import seaborn as sns  
import matplotlib.pyplot as plt
```

Essential libraries for data handling, model training, and visualization.

---

### 📥 Loading Datasets

```python
iris = load_iris()
fetch_california_housing = fetch_california_housing()
```

* `iris`: classification dataset.
* `california_housing`: regression dataset.

---

### 📊 Data Splitting

```python
x_class, y_class = iris.data, iris.target
x_reg, y_reg = fetch_california_housing.data, fetch_california_housing.target
x_train, x_test, y_train, y_test = train_test_split(x_class, y_class, test_size=0.2, random_state=42)
x_train_r, x_test_r, y_train_r, y_test_r = train_test_split(x_reg, y_reg, test_size=0.2, random_state=42)
```

---

### 📏 Feature Scaling

```python
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

scaler_r = StandardScaler()
x_train_r = scaler_r.fit_transform(x_train_r)
x_test_r = scaler_r.transform(x_test_r)
```

Standardization is applied to improve model performance and convergence.

---

### 🧮 SVM Classifier with Linear Kernel

```python
clf = SVC(kernel='linear', C=1.0, random_state=42)
clf.fit(x_train, y_train)
```

```python
y_pred_class = clf.predict(x_test)
print("Classification Accuracy:", accuracy_score(y_test, y_pred_class))
```

---

### 📊 Heatmap of Coefficients

```python
sns.heatmap(pd.DataFrame(clf.coef_, columns=iris.feature_names, index=iris.target_names), annot=True, cmap='coolwarm')
```

Visualizes how each feature influences the classification.

---

### 🧮 SVM Classifier with RBF Kernel

```python
clf1 = SVC(kernel="rbf", C=1.0, random_state=42)
clf1.fit(x_train, y_train)
y_pred_class1 = clf1.predict(x_test)
print("Classification Accuracy (RBF Kernel):", accuracy_score(y_test, y_pred_class1))
```

---

### 📈 SVM for Regression (Using SVC as proxy)

```python
reg = SVC(kernel='linear', C=1.0, random_state=42)
reg.fit(x_train_r, y_train_r)
y_pred_reg = reg.predict(x_test_r)
print("Regression MSE:", mean_squared_error(y_test_r, y_pred_reg))
```


---

## ✅ Summary

This project demonstrates:

* How to implement SVM using both linear and RBF kernels
* The use of `StandardScaler` for preprocessing
* Classification vs regression comparison using the SVM technique
* Evaluation using accuracy and MSE
* Visualization using heatmaps

